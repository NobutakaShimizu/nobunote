{"0": {
    "doc": "BKWアルゴリズム",
    "title": "BKWアルゴリズム",
    "content": "BKWアルゴリズムとは, $\\mathbb{F}_2$上のLWE探索問題(LPN探索問題)を$2^{O(n/\\log n)}$時間で解くアルゴリズムであり, Blum, Kalai, Wasserman (2003) により提案されたアルゴリズムです. ここではパラメータ$n\\in\\mathbb{N},\\rho\\in[0,1/2)$に対して以下の問題設定を考え, 便宜上LPN学習問題と呼ぶことにします: . 問題 (LPN学習問題). | 未知のベクトル$s\\in \\mathbb{F}_2^n$を考える. | ランダムサンプルオラクル$\\mathcal{O}$へアクセスする権利が与えられる. オラクル$\\mathcal{O}$に一回アクセスすると, 一様ランダムな$a\\sim \\mathbb{F}_2^n$, ベルヌーイ試行$e\\sim \\mathrm{Ber}(\\rho)$および$b=s^\\top a + e \\in \\mathbb{F}_2$に対し, 組$(a,b) \\in \\mathbb{F}_2^n \\times \\mathbb{F}_2$を取得できる. ここでベルヌーイ試行$\\mathrm{Ber}(\\rho)$とは, 他の全てのランダムネスとは独立に確率$\\rho$で$1$, 確率$1-\\rho$で$0$をとる確率変数である. | ランダムサンプルオラクルを使って未知のベクトル$s$を計算せよ. | . アルゴリズムの効率性は . | ランダムサンプルオラクル$\\mathcal{O}$へのアクセス回数 (クエリ計算量) | 時間計算量 | . によって評価できます. クエリの回数も計算量にカウントされるため, クエリ計算量は時間計算量で上から抑えられます. 従ってここでは単純化して時間計算量のみを考えます. ランダムサンプルクエリは非適応的(nonadaptive)なので, クエリの回数$m$の上界がわかっている場合は, アルゴリズムの実行時, 一番最初に$m$回クエリを行なってもそのアルゴリズムの実行に影響を与えません. このことを使ってLPN学習問題は行列の形式で定義されたLWE探索問題と(時間計算量の意味で)同値であることが簡単に示せます. 実際, $(A,As+b)$を受け取って$s$を出力するアルゴリズム$A_0$がある場合, $A$の行数を$m$とすると, まず$m$回の$\\mathcal{O}$へのクエリを使ってその応答を$(A,b)$の形にまとめ, それを$A_0$に渡すことでLPN学習問題を解くことができます. 逆にクエリ計算量$m$で解くアルゴリズムがある場合, そのアルゴリズムは$m$回のクエリに対するオラクルの応答をまとめた$(A,b)$を入力として受け取って未知のベクトル$s$を返すアルゴリズムと見做せるため, そのまま転用することで行列形式のLWE探索問題を解くことができます. 賢いアルゴリズムを見る前にまずLPN学習問題を解く自明なアルゴリズムについて考えてみましょう. そもそも未知のベクトル$s \\in \\mathbb{F}_2^n$は$2^n$通りしかないので, 全てのありうる$s$を試して最尤推定を行えば$2^{n}\\cdot \\mathrm{poly}(n)$時間でLPN学習問題を解くことができます. BKWアルゴリズムはこの自明なアルゴリズムよりも効率的にLPN学習問題を解くことができます. 定理 (BKWアルゴリズム). 任意の定数$\\rho\\in[0,1/2)$に対し, LPN学習問題を時間計算量$2^{O(n/\\log n)}$で解くアルゴリズムが存在する. なお, BKWアルゴリズムのクエリ計算量は時間計算量とほぼ同程度のオーダーになります. ",
    "url": "/nobunote/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/",
    
    "relUrl": "/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/"
  },"1": {
    "doc": "BKWアルゴリズム",
    "title": "アルゴリズムの中身",
    "content": "BKWアルゴリズムでは二つのパラメータ$g,h$ (ただし$g\\cdot h \\ge n$) に対し, $n$次元ベクトル$v\\in \\mathbb{F}_2^n$を$h$個の連続する長さ$g$のブロックに分割し, それぞれのブロックは$g$次元ベクトルとして扱います. 以後では簡単のため$n=gh$とします (そうでない場合, ベクトル$s$の後ろに$0$を適当な個数だけ連結してベクトル長を$g$または$h$の倍数にしておきます. 追加した部分は全て成分が$0$なのでラベル$b$に影響を与えることはありません). ",
    "url": "/nobunote/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E4%B8%AD%E8%BA%AB",
    
    "relUrl": "/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#アルゴリズムの中身"
  },"2": {
    "doc": "BKWアルゴリズム",
    "title": "鍵となる補題",
    "content": "アルゴリズムとその解析を述べるのに有用な以下の概念を導入します: . 定義 ($i$-サンプル). ベクトル$v \\in \\mathbb{F}_2^n$であって, 後ろ$i$個の全てのブロックに対応する成分が全て$0$であるようなものの集合を$V_i \\subseteq \\mathbb{F}_2^n$で表し, $V_i$から一様ランダムに選ばれたベクトルを$i$-サンプルと呼ぶ. 特に, オラクル$\\mathcal{O}$の出力$(a,b)$に対して$a \\sim \\mathbb{F}_2^n$は$0$-サンプルであると言えます. BKWアルゴリズムの核となるアイデアは, $i$-サンプルを用いて$i+1$-サンプルを効率的に計算できるという以下の補題に基づいています. 補題1. $L$個の独立$i$-サンプルが与えられたとき, それらを使って$L-2^g$個の独立な$(i+1)$-サンプルを出力する$O(L\\cdot 2^g)$時間アルゴリズムが存在する. さらに, このアルゴリズムで得られる各$(i+1)$-サンプルは, 入力で与えられれた$L$個の$i$-サンプルから二つを選んでその和を取ることで得られる. 図: 補題1のアルゴリズム適用後はサンプルの個数が減るが, $0$のブロックは一つ増える. 証明 証明のアイデアは非常に単純で, $L$個 の$i$-サンプルを$2^g$個のクラスと呼ばれる部分集合に分割し, それぞれのクラス内で二つのベクトルを選んで和を取ることで$(i+1)$-サンプルを得るというものです. まず, $i$-サンプル$v \\in V_i$は後ろ$i$個のブロックが全て$0$であるようなベクトルであるため, 後ろから$i+1$個目のブロックは非ゼロであることがわかります (本当は各成分がランダムに決まるのでものすごく小さい確率でこのブロックの全ての成分$0$になりますが, ここでは無視します). この非ゼロのブロックは$g$ビット文字列であり$2^g$通り存在します. 従ってこのブロックに基づいて与えられた$i$-サンプルを$2^g$個のクラスに分割することができます. 各クラス$S$に対し, 一様ランダムに$x \\sim S$を選び, 多重集合$S’=\\{x + y \\colon y \\in S\\}$を構成します. これらのベクトル$x,y$は同じクラスに属するため, その和$x+y$は後ろから$i+1$個目のブロックの全成分が$0$となるため, $V_{i+1}$の元になります. なお, $S’$の全ての元は共通の$x$に対して$x + y$という形で表されますが, $y$は先頭$h-i$個のブロックが全て独立一様ランダムなブロックであるため, 各$x+y$は$(i+1)$-サンプルとなり, しかも$y$の独立性から$S’$の元もまた独立です. アルゴリズムは 全てのクラスに対してこの操作を繰り返し, $S’$の和集合を出力します. 先ほどの議論から, 確かにこれは$(i+1)$-サンプルとなります. なお, 各クラスに対し$\\left| S’ \\right| = \\left| S \\right| - 1$であり, クラスは$2^g$個あるため, この操作は$O(L\\cdot 2^g)$時間で完了し, アルゴリズムの出力は$ |S| - 2^g$ 個の$(i+1)$-サンプルとなります. $\\square$ . ",
    "url": "/nobunote/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#%E9%8D%B5%E3%81%A8%E3%81%AA%E3%82%8B%E8%A3%9C%E9%A1%8C",
    
    "relUrl": "/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#鍵となる補題"
  },"3": {
    "doc": "BKWアルゴリズム",
    "title": "アルゴリズムの記述",
    "content": "BKWアルゴリズムではまず, $h \\cdot 2^g$回のクエリを使って$h\\cdot 2^g$個の$0$-サンプルを取得します. これらのサンプルに対して補題1を適用すると, $(h-1)\\cdot 2^g$個の$1$-サンプルを得ることができ, これらに対して改めて補題1を適用することで$(h-2)\\cdot 2^g$個の$2$-サンプルを得ます. この$(h-1)$回繰り返すと最終的に$2^g$個の$(h-1)$-サンプルを得ることができます. ここで, $(h-1)$-サンプルは先頭のブロックのみが非ゼロとなっているベクトルであることに注意しましょう. さらに, これらの先頭ブロックは$\\mathbb{F}_2^g$から独立一様ランダムに選ばれているので, 確率$(1-2^{-g})^{2^g}\\approx 1-1/\\mathrm{e}$で単位ベクトル$e_1:=[1,0,0,\\dots,0]$を含んでいるはずです. もし含まれていなければ再びクエリと補題1を使って探索することで, この単位ベクトルを高確率で見つけることができます. さらに, 補題1からこの単位ベクトルは元の$0$-サンプルのうち$2^h$個の和で表せます. これを . \\[\\begin{align*} e_1 = a_1 + \\dots + a_{2^h} \\end{align*}\\] と書きましょう (ここでは$\\mathbb{F}_2$上のベクトルとしての演算を考える). 右辺の各ベクトル$a_i$に対応するラベル$b_i$は$b_i = s^\\top a_i + e_i$を満たすので, 上式の両辺に対し$s^\\top$との内積をとると . \\[\\begin{align*} s_1 = b_1 + \\dots + b_{2^h} + \\underbrace{e_1 + \\dots + e_{2^h}}_{\\mathrm{Ber}(\\rho) \\oplus \\dots \\oplus \\mathrm{Ber}(\\rho)} \\tag{*} \\end{align*}\\] を得ます. ここでノイズに対応する部分は$2^h$個の独立なベルヌーイ試行$\\mathrm{Ber}(\\rho)$のXORとなっています. このノイズ部分を抑える次の情報理論的な補題を使うことで, $s_1$を求めることができます. 補題2. \\[\\begin{align*} \\Pr\\left[ \\underbrace{\\mathrm{Ber}(\\rho) \\oplus \\cdots \\oplus \\mathrm{Ber}(\\rho)}_{\\text{$\\ell$個}} = 0 \\right] = \\frac{1}{2} + \\frac{1}{2} \\left(1 - 2\\rho\\right)^\\ell. \\end{align*}\\] 証明 証明は$\\ell$に関する帰納法で示します. 記法の簡単のため, 主張の左辺を$p_\\ell$とおきます. 1. ベースステップ ($\\ell=1$の場合): . \\[p_1 = 1 - \\rho = \\frac{1}{2} + \\frac{1}{2}(1 - 2\\rho)\\] より, $\\ell=1$の場合に主張は確かに成り立ちます. 2. 帰納ステップ: 一般の$\\ell \\ge 2$に対しては, $p_{\\ell-1}$に対する帰納法の仮定を使って . \\[\\begin{align*} p_\\ell &amp;= (1-\\rho)\\cdot p_{\\ell-1} + \\rho\\cdot (1-p_{\\ell-1}) \\\\ &amp;= (1-\\rho)\\left( \\frac{1}{2} + \\frac{1}{2} \\left(1 - 2\\rho\\right)^{\\ell-1} \\right) + \\rho\\left( \\frac{1}{2} - \\frac{1}{2} \\left(1 - 2\\rho\\right)^{\\ell-1} \\right) \\\\ &amp;= \\text{(右辺)} \\end{align*}\\] より主張を得ます. $\\square$ . 補題2より, (*)において$s_1=b_1+\\dots+b_{2^h}$が成り立つ確率は$1/2 + (1-2\\rho)^{2^h}/2$となります. つまり, 単位行列$e_1$の和に使われたサンプルのラベルを足し合わせると$1/2$より少し大きい確率で未知のベクトルの第一成分が得られることになります. この操作は$((1-2\\rho)^{-2^h})^2\\cdot O(\\log n)$回繰り返すことによって成功確率を$1-n^{-100}$程度まで増幅できます. $s$の他の成分に関してはベクトルの成分をシャッフルして同じことを繰り返しせば, それらも同様に求めることができます. 以上より, (補題1の計算量も考慮すると)LPN学習問題は$gh\\ge n$を満たす任意の$g,h$に対して計算量 $\\mathrm{poly}\\left(n,\\left(\\frac{1}{1-2\\rho}\\right)^{2^h},2^g\\right)$で解くことができます. ",
    "url": "/nobunote/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E8%A8%98%E8%BF%B0",
    
    "relUrl": "/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#アルゴリズムの記述"
  },"4": {
    "doc": "BKWアルゴリズム",
    "title": "パラメータ$g,h$の設定",
    "content": "BKWアルゴリズムの効率性はパラメータ$g,h$の選択に大きく依存しますが, 特に$\\rho&lt;1/2$が定数の場合の計算量は . \\[\\begin{align*} \\mathrm{poly}\\left(n,\\left(\\frac{1}{1-2\\rho}\\right)^{2^h},2^g\\right) &amp;= \\mathrm{poly}\\left(n,2^{O(2^h)},2^g\\right) \\\\ &amp;= 2^{O(2^h+g)}\\cdot \\mathrm{poly}(n) \\end{align*}\\] となります. 制約$gh=n$に留意して . | $h = \\frac{\\log_2 n}{2}$ | $g = n/h = \\frac{2n}{\\log_2 n}$ とすると, 計算量は$2^{O(n/\\log n)}$となります. | . ",
    "url": "/nobunote/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BFgh%E3%81%AE%E8%A8%AD%E5%AE%9A",
    
    "relUrl": "/docs/learning_with_error/BKW%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/#パラメータghの設定"
  },"5": {
    "doc": "Goldreich-Levinの定理",
    "title": "Goldreich-Levinの定理",
    "content": "Goldreich-Levinの定理とは, Goldreich, Levin (1989)による定理です. 様々な文脈で解釈できる有名な定理で, 主に . | 任意の一方向性置換(one-way permutation)からハードコア述語を構成する定理 | アダマール符号の局所リスト復号を与える定理 | Boolean関数の大きいフーリエ級数の列挙アルゴリズムを与える定理 | . と理解されています. ただしここではそれぞれの文脈の前知識を必要としない解説をします. イメージとしては, Goldreich-Levinの定理とは, 任意のBoolean関数$f$がオラクルアクセスとして与えられたとき, その関数に「近い」全ての線形関数を効率的に列挙するアルゴリズムを与える定理と言えます. ",
    "url": "/nobunote/docs/average_case_complexity/Goldreich-Levin/",
    
    "relUrl": "/docs/average_case_complexity/Goldreich-Levin/"
  },"6": {
    "doc": "Goldreich-Levinの定理",
    "title": "ウォームアップ1. 線形関数の復元",
    "content": "まずは導入として, 以下の問題を考えてみましょう. 問題(線形関数の復元). あるベクトル$c=(c_1,\\dots,c_n) \\in \\{0,1\\}^n$に対して . \\[\\begin{align*} f(x_1,\\dots,x_n) = \\sum_{i\\in[n]} c_i x_i \\bmod 2 \\end{align*}\\] と表せる関数 $f \\colon \\{0,1\\}^n \\to \\{0,1\\}$ がオラクルアクセスとして与えられたとき, ベクトル$c \\in \\{0,1\\}^n$を$\\mathrm{poly}(n)$時間で求めよ. 計算時間が指数時間かかって良いのであれば, 全ての$x \\in \\{0,1\\}^n$に対して$f(x)$にオラクルアクセスして$f$の真理値表を取得して, そして全ての$c\\in \\{0,1\\}^n$を列挙して線形関数を列挙して, 真理値表と合致する線形関数を求めればよいです. ところがそもそも$f$が線形関数であることから . \\[\\begin{align*} f(1,\\underbrace{0,\\dots,0}_{n-1\\text{個}}) = c_1 \\end{align*}\\] から$c_1$を直接求められます. より一般に各単位ベクトル上での$f$の値にオラクルアクセスすればよく, 以下のアルゴリズムによって求められます. アルゴリズム1. | 各$i=1,\\dots,n$ に対して以下を行う: . | $e_i$を$i$番目の成分が$1$, それ以外の成分が$0$であるような単位ベクトルとする. | $c_i \\leftarrow f(e_i)$とする. | . | $c=(c_1,\\dots,c_n)$を出力する. | . ",
    "url": "/nobunote/docs/average_case_complexity/Goldreich-Levin/#%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%A0%E3%82%A2%E3%83%83%E3%83%971-%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0%E3%81%AE%E5%BE%A9%E5%85%83",
    
    "relUrl": "/docs/average_case_complexity/Goldreich-Levin/#ウォームアップ1-線形関数の復元"
  },"7": {
    "doc": "Goldreich-Levinの定理",
    "title": "ウォームアップ2. 線形関数の復元 (ノイズ付き)",
    "content": "では, ウォームアップ1を少し難しくした次の問題を考えてみましょう. 以後, 二つのベクトル $x,y\\in \\{0,1\\}^n$ の $\\mathbb{F}_2$ 上での内積を . \\[\\begin{align*} \\langle x,y \\rangle = \\sum_{i\\in[n]} x_i y_i \\pmod 2 \\end{align*}\\] と表すことにします. 問題(線形関数の弱いノイズからの復元). あるベクトル$c=(c_1,\\dots,c_n) \\in \\{0,1\\}^n$に対して . \\[\\begin{align} \\Pr_{x \\sim \\{0,1\\}^n} \\left[ f(x) = \\langle c,x \\rangle \\right] \\ge 0.99 \\tag{1} \\end{align}\\] を満たす関数 $f \\colon \\{0,1\\}^n \\to \\{0,1\\}$ がオラクルアクセスとして与えられたとき, ベクトル$c \\in \\{0,1\\}^n$を$\\mathrm{poly}(n)$時間で求めよ. ここで, 上式の確率は一様ランダムに選ばれた$x\\sim \\{0,1\\}^n$に関する確率を考える. 上図では$c=(101)$に対して$x\\mapsto \\langle c,x\\rangle$という関数の真理値表のうち二つのビットだけ反転(赤字)したものがオラクルアクセスとして与えられた状態で係数ベクトル$c$を復元する問題を表現しています. このような「ノイズがのった線形関数」の局所的な情報から元の線形関数の情報を取得せよという問題を考えています. 例えばアルゴリズム1を考えてみましょう. 今回の問題設定では, 各単位ベクトル上でオラクルアクセスの値$f(e_i)$が必ずしも$c_i=\\langle c,e_i \\rangle$と等しいとは限りません. 例えば . \\[\\begin{align*} f(x) = \\begin{cases} 1 - c_i &amp; \\text{if $x=e_i$ is a unit vector},\\\\ \\langle c,x\\rangle &amp; \\text{otherwise} \\end{cases} \\end{align*}\\] で定まる関数$f$は, $n$が十分大きければ式(1)を満たしますが, アルゴリズム1の出力は正解$c$とは異なるベクトルになってしまいます. このように, この問題設定で考える$f$はアルゴリズムに応じて「いじわるに」(敵対的に)オラクルアクセスとして与えられます. そもそも, 任意の決定的多項式時間アルゴリズムは$f$の真理値表のうち$\\mathrm{poly}(n)$個の成分しか見ません. しかし$f$を敵対的に選ぶときは$0.01\\cdot 2^n$個の$x$に対して$f(x)$の値を自由に選ぶことができますので, $\\mathrm{poly}(n) &lt; 0.01\\cdot 2^n$を満たす十分大きな$n$に対してはこの多項式時間アルゴリズムのオラクルアクセスの返答を自由に選べてしまうので係数ベクトル$c$の情報を得ることはできません. つまり情報理論的にこの問題は決定的多項式時間アルゴリズムでは解けないことになります (もっというと計算時間は少なくとも$0.01\\cdot 2^n$は必要です). 一見すると非常に難しそうに見えますが, 実はランダムネスの力を借りると解くことができます. 上記の問題を確率$0.99$で解く$O(n\\log n)$時間乱択アルゴリズムが存在する. 証明 任意の単位ベクトルを$e_i$とと$x\\in {0,1}^n$に対して . \\[\\begin{align*} \\langle c, e_i \\rangle = \\langle c, x+e_i \\rangle - \\langle c,x \\rangle \\end{align*}\\] が成り立つので, 何らかの$x$に対して$\\langle c,x+e_i \\rangle$と$\\langle c,x \\rangle$の値が求められれば$f(e_i)$を計算することができます (ここでベクトルの加算は$\\mathbb{F}_2$上で考えます). そこで$x\\in {0,1}^n$を一様ランダムに選んだとき, $x+e_i \\in {0,1}^n$もまた一様ランダムなベクトルとなるので, 任意の固定した$i\\in[n]$に対して . \\[\\begin{align*} &amp;\\Pr_{x\\sim\\{0,1\\}^n} \\left[ f(x) = \\langle c,x \\rangle \\text{ and } f(x+e_i) = \\langle c,x+e_i \\rangle \\right] \\\\ &amp;\\ge 1 - \\Pr_x \\left[ f(x) \\ne \\langle c,x \\rangle \\right] - \\Pr_x \\left[f(x + e_i) \\ne \\langle c,x+e_i \\rangle \\right] \\\\ &amp;\\ge 0.98 \\tag{2} \\end{align*}\\] となります. このことから, 一様ランダムな$x\\sim {0,1}^n$に対して確率$0.98$で$c_i = \\langle c,e_i \\rangle = f(x+e_i) - f(x)$を満たします. この操作を$O(\\log n)$回繰り返して多数決をとれば確率$\\ge 1-\\frac{1}{100n}$で$c_i$が得られるので, 全ての$i \\in [n]$に対して同様の操作を行えば, $i$に関するunion boundから確率$0.99$で$c=(c_1,\\dots,c_n)$を得られます. $\\square$ . まとめると命題のアルゴリズムは以下となります: . アルゴリズム2. | 各$i=1,\\dots,n$に対して以下を行う: . | 各$t=1,\\dots,100\\log_2 n$に対して以下を行う: . | 一様ランダムなベクトル$x \\sim {0,1}^n$を選ぶ. | オラクルアクセスを用いて$b_t = f(x+e_i) - f(x)$とする. | . | $(b_t)$の中で多数決をとり, それを$c_i$とする. | . | $c=(c_1,\\dots,c_n)$を出力する. | . ",
    "url": "/nobunote/docs/average_case_complexity/Goldreich-Levin/#%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%A0%E3%82%A2%E3%83%83%E3%83%972-%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0%E3%81%AE%E5%BE%A9%E5%85%83-%E3%83%8E%E3%82%A4%E3%82%BA%E4%BB%98%E3%81%8D",
    
    "relUrl": "/docs/average_case_complexity/Goldreich-Levin/#ウォームアップ2-線形関数の復元-ノイズ付き"
  },"8": {
    "doc": "Goldreich-Levinの定理",
    "title": "Goldreich-Levinの定理: 強いノイズが乗った線形関数の復元",
    "content": "ウォームアップ2の問題設定では線形関数の真理値表のうち1%の成分が反転した場合でも乱択を用いれば$O(n\\log n)$時間で復元できることを証明しました. ではこのノイズ率$0.01$はどこまで大きくできるでしょうか? 以後の議論を明確に述べるために, 二つの関数間の距離の概念を導入します: . 二つの関数$f,g\\colon \\{0,1\\}^n \\to \\{0,1\\}$の距離$\\mathrm{dist}(f,g)$を . \\[\\begin{align*} \\mathrm{dist}(f,g):=\\Pr_{x\\sim \\{0,1\\}} \\left[f(x)\\ne g(x)\\right] \\end{align*}\\] とする. すなわち, $f$と$g$の真理値表を長さ$2^n$のベクトルとみなしたときの(正規化された)ハミング距離を考えていることになります. この距離を用いてウォームアップ2の問題設定を一般的な形で述べ直します. 問題. あるベクトル$c\\in \\{0,1\\}^n$を係数ベクトルとして持つ線形関数$g\\colon x\\mapsto \\langle c,x\\rangle$に対し, $\\mathrm{dist}(f,g)\\le \\delta$を満たす関数$f$へのオラクルアクセスが与えられたとき, $c$を求めよ. すなわち, 知りたい関数$g$から半径$\\delta$以内にある関数$f$の真理値表の局所的な情報のみを用いて$g$の係数ベクトルを求めよという問題になっています. 詳細は割愛しますが, この問題は冒頭にも述べたように . | Boolean関数の線形近似 | 一方向性置換からハードコア述語の構成 | アダマール符号の局所リスト復号 | . といった文脈において直接的に応用されています. ウォームアップ2では$\\delta\\le 0.01$に対してこの問題が効率的に解けることを証明しました. では$\\delta$はどこまで大きくできるでしょうか? アルゴリズム2では最後に多数決で成功確率を増幅させているわけですが, そのためには一回の試行の成功(すなわち $f(x)=\\langle c,x\\rangle$かつ $f(x+e_i)=\\langle c,x+e_i \\rangle $という事象)の確率が$0.5$を超えていなければなりません. この確率は式(2)で抑えていたわけですが, この最後の値が$0.5$を超えるには . \\[\\begin{align*} \\delta = \\Pr_x \\left[f(x) \\ne \\langle c,x \\rangle\\right] &lt; 0.25 \\end{align*}\\] でなければなりません. つまり, アルゴリズム2は$\\delta &lt; 0.25$でなければ成功する保証がないということになります. 実は$\\delta \\ge 0.25$の場合は復元すべき線形関数が一意に定まるとは限りません. 一意復元できない例 例えば$\\delta=0.25$とし, $c_1=(0,\\dots,0),c_2=(1,0,\\dots,0)$として二つの線形関数 . \\[\\begin{align*} g_1 \\colon x &amp;\\mapsto \\langle c_1, x \\rangle = 0, \\\\ g_2 \\colon x &amp;\\mapsto \\langle c_2, x \\rangle = x_1 \\end{align*}\\] を考えてみましょう. 最初の線形関数$g_1$は恒等的に$0$を出力する定数関数ですので, . \\[\\begin{align*} g' \\colon x \\mapsto x_1\\cdot x_2 \\end{align*}\\] という関数を考えると$\\mathrm{dist}(g_1,g’)\\le 0.25$を満たします. この関数$g’$は$g’(x)=1 \\iff x_1=x_2=1$ですので . | $x_1 = 0$のとき, $g_2(x)=g’(x)=0$ | $x_1 = 1$のとき, $g_2(x)=1$, $g’(x)=x_2$ | . より . \\[\\begin{align*} \\mathrm{dist}(g_2,g')=\\Pr_x [g_2(x) \\ne g'(x)] = \\Pr_x[x_1=1\\text{ and }x_2=0] = 0.25 \\end{align*}\\] です. つまり$g’$は$g_1,g_2$どちらからも距離$0.25$だけ離れている関数となっているため, アルゴリズムが$g’$をオラクルアクセスとして与えられたとき, $g_1$と$g_2$はどちらも正解の条件に当てはまってしまうのです. ところが, 実は任意の関数$f\\colon \\{0,1\\}^n\\to \\{0,1\\}$に対して, $\\mathrm{dist}(f,g)\\le 0.5-\\varepsilon$を満たす線形関数$g$は高々$O(\\varepsilon^{-2})$個しかないことが知られています. Goldreich-Levinの定理とはそのような全ての線形関数$g$を多項式時間で列挙できることを主張する定理です. 定理 (Goldreich-Levinの定理). 任意の関数$f\\colon \\{0,1\\}^n\\to \\{0,1\\}$に対し, $f$へのオラクルアクセスとパラメータ$\\varepsilon&gt;0$が与えられたときに$\\mathrm{dist}(f,g)\\le 0.5 - \\varepsilon$を満たす全ての線形関数$g$の係数ベクトルを確率$2/3$で出力する$\\mathrm{poly}(n,1/\\varepsilon)$時間乱択アルゴリズムが存在する. 証明のアイデア . アルゴリズムのベースラインはアルゴリズム2と同じです. ランダムな$x$に対して$f(x+e_i)-f(x)$を計算し, これを繰り返して$x$に関して多数決をとることによって係数ベクトルの第$i$成分$c_i$を確率$1-1/n$で復元し, これを各$i\\in[n]$に対して行うというものです. しかしこの方法では, 求めたい線形関数$g$に対して$g(x+e_i)$と$g(x)$の二つの値を得なければならず, $f$へのオラクルアクセスを使って得ようとすると$f$のノイズが小さくなければ精度を保証できません. そこで, Goldreich-Levinのアルゴリズムでは, $g(x)$の値を推測するという方針をとります. 例えば$x_1,\\dots,x_T$に関して$f(x_j + e_i) - f(x_j)$の多数決をとることを考えましょう. このとき, $(g(x_1),\\dots,g(x_T)) \\in \\binset^T$は$2^T$通りしかないので, 各$(a_1,\\dots,a_T)\\in \\binset^T$に対して . | ${}^{\\forall}j\\in[T],g(x_j)=a_j$だと思って$f(x_j+e_i) - a_j$を計算する. ここで, $x_j\\sim\\binset^n$より確率$\\frac{1}{2}+\\varepsilon$で$f(x_j+e_i)=g(x_j+e_i)$となる. | $j$に関して多数決をとって, その結果を$\\widetilde{c}_i$の推測値とする. | 全ての$i=1,\\dots,n$に対して$\\widetilde{c}_i$を推測して$\\widetilde{c}=(\\widetilde{c}_1,\\dots,\\widetilde{c}_n)$を出力リストに加える. | . という操作を行うことによって$2^T$個の$c$の候補を得ることができます (全ての$(a_1,\\dots,a_T)\\in \\binset^T$に対して行なっているので, どれかの$(a_1,\\dots,a_T)$では求めたい線形関数$g$が$g(x_j)=a_j$を満たすはずです). ここでは, オラクルアクセスは$f(x_j+e_i)$の取得のみに用いており, $x_j$が$\\binset^n$上で一様ランダムなベクトルなので$f(x_j+e_i)=\\inprod{c,x_j+e_i}$となる確率は$\\frac{1}{2}+\\varepsilon$となります. 各$i=1,\\dots,n$に関するunion boundを適用するには多数決の結果が確率$1-\\frac{1}{n}$で正しくなくてはならず, そのためには少なくとも $T \\ge \\frac{\\log n}{\\varepsilon^2}$でなければなりません. 残念ながらこのアルゴリズムは$2^T$通りの推定を列挙する必要があるため, その時間計算量は少なくとも$2^T \\ge n^{\\Omega(1/\\varepsilon^2)}$以上となり, Goldreich-Levinの定理で要求される計算量$\\poly(n,1/\\varepsilon)$よりも大きくなってしまいます. この計算量を改善するために, $x_1,\\dots,x_T$をペア独立に生成して, 列挙すべき$(a_1,\\dots,a_T)$の個数を少なくするという工夫を行います. ペア独立性+線形性を用いた多数決 . オラクル$f$に近い線形関数の一つを$g$とし, この関数を求めることを考えます. 関数$g$が線形関数なので, 点$x_1,\\dots,x_T$における$g$の値が$a_1,\\dots,a_T$であるとき, 全ての非空な$S\\subseteq[T]$に対して 点$x_S=\\sum_{i\\in S}x_i$において$g(x_S)=\\sum_{i\\in S} a_i$が成り立ちます. 最終的には全ての$(a_1,\\dots,a_T)\\in\\binset^T$を列挙するアルゴリズムを考えるので, 以後では$g(x_j)=a_j$が成り立つような$(a_1,\\dots,a_T)$に対して議論していきます. 独立一様ランダムに$x_1,\\dots,x_T \\sim \\binset^n$を選んだとき, ペア独立の例2より確率変数族 $(x_S)$はペア独立になります. また, $x_S$上での$f$の推定値は$a_S=\\sum_{i\\in S}a_i$ですので, $S\\ne \\emptyset$を列挙して$f(x_S+e_i)-a_S$の多数決をとることによって$c_i$の推定値$\\widetilde{c}_i$を計算できます. ここで線形関数$g$が$\\dist(f,g) \\le 0.5-\\varepsilon$を満たすとすると, $x_S \\in \\binset^n$の周辺分布は一様なので . \\[\\begin{align*} \\Pr\\qty[ f(x_S+e_i)=g(x_S+e_i) ] \\ge \\frac{1}{2} + \\varepsilon \\end{align*}\\] となります. まとめると, 確率変数$X_S$を \\(X_S = f(x_S+e_i) - a_S \\pmod 2\\) とすると, $X_S$は確率$\\frac{1}{2}+\\varepsilon$で$1$であり, しかも族$(X_S)_{S\\ne \\emptyset}$はペア独立性を持ちます. ここで \\(Z = \\sum_{S\\ne\\emptyset} X_S\\), $N=2^T-1$とすると$\\E[Z]\\ge \\qty(\\frac{1}{2} + \\varepsilon) N$および 各$X_S$の分散は高々$1$なので, ペア独立な確率変数族の和に対するChebyshevの不等式より, . \\[\\begin{align*} \\Pr\\qty[ S \\le \\frac{N}{2} ] &amp;= \\Pr\\qty[ Z \\le \\E[Z] - \\varepsilon N] \\\\ &amp;\\le \\Pr\\qty[ \\abs{Z - \\E[Z]} \\ge \\varepsilon N] \\\\ &amp;\\le \\frac{1}{\\varepsilon^2 N}. \\end{align*}\\] よって, $N \\ge 10n/\\varepsilon^2$ならば, 確率$1-\\frac{1}{10n}$で$(X_S)$らの多数決が$g(e_i)$に等しくなるので, 各$i\\in[n]$に関するunion boundより, 確率$0.9$で$g$を復元できます (詳細はアルゴリズム3参照). オラクル$f$に近い各$g$に対してアルゴリズム3は確率$0.9$で$g$を復元します, 多項式回だけ繰り返すことによってこの復元確率を$1-2^{\\poly(n)}$まで増幅できるので, その後に$g$に関するunion boundをとればGoldreich-Levinの定理が示されます (ありうる$g$は線形関数であることを踏まえれば高々$2^n$個ですが, 実際には$f$に近いという条件もあるのでその個数は$O(1/\\varepsilon^2)$で抑えられることが知られています). なお, $N = 2^T -1 \\ge 10n/\\varepsilon^2$であれば上記のアルゴリズムは動くので, アルゴリズムの計算量は$\\poly(n)\\cdot O(2^T) = \\poly(n,1/\\varepsilon)$となります. アルゴリズム . アルゴリズム3. | パラメータ$T\\in\\Nat$を, $2^T &gt; 10n/\\varepsilon^2$を満たすように選ぶ. | 各$a=(a_1,\\dots,a_T)\\in \\binset^T$に対して以下を行う: . | 独立一様ランダムにベクトル$x_1,\\dots,x_T \\sim \\binset^n$を選ぶ. | 各$i=1,\\dots,n$に対して以下を行う: . | 各非空な$S\\subseteq [T]$に対して$b_S = f(x_S+e_i) - a_S$を計算する. ここで\\(x_S := \\sum_{i\\in S} x_i\\), \\(a_S := \\sum_{i\\in I} a_i\\). | $(b_S)_{S\\ne \\emptyset}$の中で多数決をとり, その結果を$c_i$とする. | . | $c_a = (c_1,\\dots,c_n) \\in \\binset^n$とする. | . | $(c_a)_{a\\in \\binset^T}$を出力する. | . アルゴリズム3の計算量 . ループの外であらかじめ各$x_S$を計算しておくと ステップ2-bの各反復で計算量$O(2^T)$で実装できます. この反復が合計で$2^T\\cdot n$回繰り返されるため, 全体の計算量は . \\[\\begin{align*} O(n \\cdot (2^T)^2) = O(n N^2) = O(n^3/\\varepsilon^4) \\end{align*}\\] となります. ",
    "url": "/nobunote/docs/average_case_complexity/Goldreich-Levin/#goldreich-levin%E3%81%AE%E5%AE%9A%E7%90%86-%E5%BC%B7%E3%81%84%E3%83%8E%E3%82%A4%E3%82%BA%E3%81%8C%E4%B9%97%E3%81%A3%E3%81%9F%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0%E3%81%AE%E5%BE%A9%E5%85%83",
    
    "relUrl": "/docs/average_case_complexity/Goldreich-Levin/#goldreich-levinの定理-強いノイズが乗った線形関数の復元"
  },"9": {
    "doc": "Kučeraのアルゴリズム",
    "title": "Kučeraのアルゴリズム",
    "content": "Kučeraのアルゴリズムとは$k\\ge \\sqrt{n\\log n}$に対して埋め込みクリーク探索問題を解くアルゴリズムです. アルゴリズム自体は非常にシンプルで, 次数の大きい順に$k$個の頂点を出力するだけです. Kučeraのアルゴリズム . | 次数の大きい順に頂点を並び替え, $v_1,\\dots,v_n$とする. | $C=\\{v_1,\\dots,v_k\\}$を出力する. | . なぜこれで解けるのでしょうか? 直感的には, ランダムグラフ$G(n,1/2)$に大きなクリーク$C\\subseteq [n]$を追加すると, $C$に属する頂点の次数は$k/2$増えます. $C$の外側の頂点の次数は期待値が$n/2$ですがそこから標準偏差$\\pm O(\\sqrt{n})$だけずれます. 実際には$n$個の頂点があるので, 最大次数は期待値から$O(\\sqrt{n\\log n})$だけ離れます. 従って, $C$内の頂点の次数の増分$k/2$が$O(\\sqrt{n\\log n})$より大きければ, $C$内の頂点の次数は$C$外の頂点の次数より大きくなるので, 次数の大きい順に$k$個の頂点を出力すればそれが$k$-クリークになっているはずです. ",
    "url": "/nobunote/docs/planted_clique/Kucera%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/",
    
    "relUrl": "/docs/planted_clique/Kucera%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/"
  },"10": {
    "doc": "問題の平均時困難性",
    "title": "問題の平均時困難性",
    "content": "計算問題が平均時困難であるという性質は, 多くの入力上でその問題を解くことが困難であることを意味します. NP困難性などの最悪時困難性では困難な入力の存在性を議論するのに対し, 平均時困難性ではその困難な入力が入力全体に対しどの程度の割合を占めるかを議論します. ここでは判定問題の平均時困難性を導入します; 一般の問題についても同様に平均時困難性の概念を定義できます. まず, 導入として関数$f\\colon \\binset^n\\to\\binset$の平均時困難性を定義します. 定義 (関数の平均時困難性) . 自然数$n\\in\\Nat$を固定し, $\\calA = \\{ A\\colon \\binset^n \\to \\binset \\}$を関数の族とする. パラメータ$\\gamma\\in[0,1]$に対して関数$f\\colon\\binset^n\\to \\binset$が$\\calA$に対して$\\gamma$-困難であるとは, . \\[\\begin{align*} {}^\\forall A \\in \\calA,\\Pr_{x\\sim\\binset^n}\\left[ A(x) = f(x) \\right] \\le 1-\\gamma \\end{align*}\\] を意味する. なお, 基本的に$\\calA$としては定数関数$A_b\\colon x\\mapsto b$を含み, $A_0$と$A_1$の少なくとも一方は$1/2$以上の割合の$x\\sim\\binset^n$に対して$A(x)=f(x)$となるので, 考える$\\gamma$の範囲は$\\gamma \\le 1/2$となります. 判定問題を考える際は入力長$n$は固定されず, 関数$f \\colon \\binset^*\\to \\binset$を考えるので以下のように定義します. 定義 (判定問題の平均時困難性) . 関数族$\\calA = \\{ A\\colon \\binset^*\\to\\binset \\}$を考え, $\\gamma\\colon \\Nat\\to[0,1]$を関数とする. 判定問題 $f \\colon \\binset^* \\to \\binset$が$\\calA$に対して$\\gamma(n)$-困難であるとは, 十分大きな全ての$n$に対して . \\[\\begin{align*} {}^\\forall A\\in \\calA,\\Pr_{x\\sim\\binset^n} \\left[ A(x)=f(x) \\right] \\le 1-\\gamma(n) \\end{align*}\\] を意味する. 引数$n$は常に入力長なので, しばし省略して$\\gamma$-困難と表す. ",
    "url": "/nobunote/docs/average_case_complexity/average_case_hardness/",
    
    "relUrl": "/docs/average_case_complexity/average_case_hardness/"
  },"11": {
    "doc": "エクスパンダーグラフ",
    "title": "エクスパンダーグラフ",
    "content": " ",
    "url": "/nobunote/docs/tools/expander/",
    
    "relUrl": "/docs/tools/expander/"
  },"12": {
    "doc": "Home",
    "title": "Home",
    "content": "This is a private memo of my own. ",
    "url": "/nobunote/",
    
    "relUrl": "/"
  },"13": {
    "doc": "よく使う道具",
    "title": "よく使う道具",
    "content": "ここでは様々な場面でよく出てくる道具をまとめて紹介していきます. ",
    "url": "/nobunote/docs/tools/",
    
    "relUrl": "/docs/tools/"
  },"14": {
    "doc": "Learning with Error",
    "title": "Learning with Error (LWE) とは?",
    "content": "Learning with Error (LWE) とはノイズが乗った線形方程式を解けという非常にシンプルな問題です. ノイズが乗っていない場合はガウスの消去法などを用いて簡単に解けますが, ノイズが乗った設定では適切なパラメータ下では . | 情報理論的には最尤推定 (全探索) で解ける. | しかし, 多項式時間で解けるかどうかは不明 | . という状況になっています. そして, これが情報論的なtractabilityと計算量的なtractabilityの間の非自明なギャップであろうと広く信じられています. LWEの計算量的困難性を仮定すると学習理論や暗号などの分野において様々な計算量的下界が成り立ち, 以下に挙げる様々な利点から次世代の暗号技術(特に耐量子暗号)の核になることが期待されている重要な問題です: . | 公開鍵暗号方式など様々な暗号学的プリミティブを設計できる. | 格子上の問題(最短ベクトル問題など)の最悪時困難性を仮定するとLWEの平均時困難性が成り立つという結果が知られている (最悪時から平均時への帰着). | 上記の格子上の問題を解く効率的な量子アルゴリズムの存在性は長年未解決. | . ",
    "url": "/nobunote/docs/learning_with_error/#learning-with-error-lwe-%E3%81%A8%E3%81%AF",
    
    "relUrl": "/docs/learning_with_error/#learning-with-error-lwe-とは"
  },"15": {
    "doc": "Learning with Error",
    "title": "問題の定義",
    "content": "行列$A \\in \\mathbb{F}^{m\\times d}$とベクトル $b = As \\in \\mathbb{F}^m$ (ただし $s \\in \\mathbb{F}^d$は秘密のベクトル) が入力として与えられたときに $s $ を復元することはできるでしょうか? この問題は単に連立一時方程式 . \\[\\begin{align} As = b \\end{align}\\] を解くだけですので, ガウスの消去法などを用いて多項式時間で解けます. では, 与えられるベクトル$b$が小さいノイズを含む場合はどうでしょうか? 具体的には, 入力として与えられるベクトル$b$がノイズベクトル$e \\in \\mathbb{F}^m$に対して$b=As + e$を満たす場合を考えます. ここで$e$はランダムなベクトルであり, 各成分が独立に$\\mathbb{F}$上の同じ分布に従って生成されるものとします. このような設定は線形関数の学習を考えると(有限体であることを除けば)非常にありふれた自然な設定であろうことがわかります. つまり, 様々な評価点とその点におけるラベルが与えられたときに, 未知の線形関数 $ \\mathbb{F}^d \\ni x \\mapsto s^\\top x $ を学習する際, ラベルにノイズが乗る設定を考えると上記のような問題が自然に現れます. Learning with Error (以下, LWE問題) は平均時の問題, すなわち入力が何かしらの分布に従って生成される問題であり, ここでは秘密のベクトル $s \\in \\mathbb{F}^d$ と係数行列 $A \\in \\mathbb{F}^{m\\times d}$ が一様ランダムに選ばれたとき, 行列$A$と$b=As+e$が入力として与えられます. $\\mathbb{F}$を有限体, $m,d\\in \\mathbb{N}$をパラメータ, そして$\\chi$を$\\mathbb{F}$上の分布とする. 一様ランダムな$A\\sim \\mathbb{F}^{m\\times d}$, $s\\sim \\mathbb{F}^d$, およびノイズベクトル$e \\sim \\chi^m$に対し, 三つ組$(A,As+e,s)$の周辺分布を$\\mathsf{LWE}_{\\mathbb{F},m,d,\\chi}$で表す. ここで, $\\chi^m$は$\\mathbb{F}^m$上の分布であり, 各成分が$\\chi$から独立に選ばれたベクトルの分布を表す. パラメータ$\\mathbb{F},m,d,\\chi$が明らかな場合は単に$\\mathsf{LWE}$で表す. パラメータ$m$をサンプル数, $d$を次元, $\\chi^m$をノイズ分布, $s$を秘密のベクトル, $b$をラベルと呼ぶ. 代表的なノイズ分布としては以下の二つが挙げられます: . | ランダムスパースベクトル: 体として$\\mathbb{F}=\\mathbb{F}_2$を考え, $\\chi$はパラメータ$\\theta\\in[0,1]$に対して$\\Pr[\\chi=1]=\\theta$を満たすもの. パラメータ$\\theta$が小さければ, ノイズベクトル$e\\sim\\chi^m$は非ゼロ要素数の個数がおおよそ$m\\theta$となる. | 離散ガウス分布: 位数が素数$p$であるような有限体$\\mathbb{F}_p$に対し$\\chi$は$\\mathbb{F}_p$上の分布であり, パラメータ$\\sigma$に対し, $\\chi$は$\\Pr[\\chi = x] \\propto \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$で定まる分布を考える (ここの右辺では$x\\in{0,1,\\dots,p-1}$を非負整数として扱って確率を計算する). | . また, 特殊ケース$\\mathbb{F} = \\mathbb{F}_2$におけるLWE問題は特にLPN(Learning Parity with Noise)問題と呼ばれます. LWE問題では$(A,b,s) \\sim \\mathsf{LWE}$に対し, $(A,b)$の情報から$s$を復元せよという問題を考えます. 実際には様々な問題設定があり, 代表的なものとして探索問題 (search), 判定問題 (decision)などが考えられています. ",
    "url": "/nobunote/docs/learning_with_error/#%E5%95%8F%E9%A1%8C%E3%81%AE%E5%AE%9A%E7%BE%A9",
    
    "relUrl": "/docs/learning_with_error/#問題の定義"
  },"16": {
    "doc": "Learning with Error",
    "title": "探索問題",
    "content": "探索問題とは, その名の通り, 秘密のベクトル$s$を復元せよという問題です. 分布$\\mathsf{LWE}_{\\mathbb{F},m,d,\\chi}$に従って選ばれた$(A,b,s)$に対し, $(A,b)$を入力として受け取って$s$を出力せよという問題を探索LWE問題という. アルゴリズム$\\mathcal{A}$は . \\[\\begin{align*} \\Pr_{(A,b,s) \\sim \\mathsf{LWE}} \\left[ \\mathcal{A}(A,b) = s \\right] \\ge \\gamma \\end{align*}\\] を満たすとき, 探索LWE問題を成功確率$\\gamma$で解くという. サンプル数$m$が小さいと, 与えられた$(A,b)$に対して $As \\approx b$を満たす$s$は複数存在しえるため, 秘密のベクトル$s$を復元することはできません. これを情報理論的に解けないと言うことがあります. 一方で$m$が十分大きいとき, 全てのありうる$s$を試して$As\\approx b$を見れば, $(A,b,s) \\sim \\mathsf{LWE}$に関して非常に高確率で秘密のベクトル$s$を復元できます. これを, サンプル数$m$が十分大きいときは情報理論的に解けるという言い方をします. もちろん, 情報理論的に解けるからといってそれが効率的に解けるかどうかは分かりません. ",
    "url": "/nobunote/docs/learning_with_error/#%E6%8E%A2%E7%B4%A2%E5%95%8F%E9%A1%8C",
    
    "relUrl": "/docs/learning_with_error/#探索問題"
  },"17": {
    "doc": "Learning with Error",
    "title": "判定問題",
    "content": "アルゴリズムは$(A,b) \\in \\mathbb{F}^{m\\times d}\\times \\mathbb{F}^m$を与えられます. ただし入力$(A,b)$は以下の二つどちらかの分布に従って生成されます: . | $(A,b,s) \\sim \\mathsf{LWE}$に対して$(A,b)$の周辺分布. | $\\mathbb{F}^{m\\times d}\\times \\mathbb{F}^m$上の一様分布. | . 判定問題では, 入力が上記どちらの分布に従って生成されたかを判別する問題です. 出力値が0または1のアルゴリズム $\\mathcal{A}$ は . \\[\\begin{align*} \\left| \\Pr_{(A,b,s) \\sim \\mathsf{LWE}} \\left[ \\mathcal{A}(A,b)=1 \\right] - \\Pr_{\\substack{A\\sim \\mathbb{F}^{m\\times d} \\\\ b \\sim \\mathbb{F}^m}} \\left[ \\mathcal{A}(A,b) = 1 \\right] \\right| \\ge \\gamma \\end{align*}\\] を満たすとき, 判定LWE問題をアドバンテージ$\\gamma$で解くという. サンプル数$m$が十分大きいとき, 一様ランダムな$A\\sim \\mathbb{F}^{m\\times d},b\\sim \\mathbb{F}^m$に対して$As\\approx b$を満たす$s\\in \\mathbb{F}^d$は存在しない. 一方で$(A,b)$が$\\mathsf{LWE}$の分布から生成された場合はそのような$s$は必ず存在する. 従って与えられた$(A,b)$が$\\mathsf{LWE}$から来たのか, 一様分布から来たのかは秘密のベクトルの存在性を解けば判定できることになる. このような背景で, $\\mathsf{LWE}$と一様分布の識別を判定問題と呼んでいる. ",
    "url": "/nobunote/docs/learning_with_error/#%E5%88%A4%E5%AE%9A%E5%95%8F%E9%A1%8C",
    
    "relUrl": "/docs/learning_with_error/#判定問題"
  },"18": {
    "doc": "Learning with Error",
    "title": "学習としてのLWE問題",
    "content": "LWE問題はなぜLearningなのでしょうか? 実は, LWE問題は線形関数をノイズ下で学習するタスクとみなすこともできます. 大雑把に言えば学習とは, 何かしら未知の関数 $f\\colon \\mathcal{X} \\to \\mathcal{L}$ があって, サンプルと呼ばれる幾つかの点の集合$(x_1,f(x_1)),\\dots,(x_m,f(x_m))$が与えられたとき, この関数$f$を模倣する関数$\\tilde{f}$を構成せよというタスクを意味し, このタスクを行うアルゴリズムを学習アルゴリズムといいます. 基本的には任意の関数を扱うことはせず, $f$は何かしらの性質(例えば線形性)を持つことを仮定します. ここでは学習の概念については深掘りせず, ひとまずLWE問題を学習タスクとして捉えられることを説明します. LWE問題では未知のベクトル$s\\in \\mathbb{F}^n$に対して, 一様ランダムな$A \\sim \\mathbb{F}^{m\\times n}$とノイズベクトル$e \\in \\mathbb{F}^m$に対して$b=As+e$および$A$が入力として与えられ, $s$を求めることを目標としていました. そこで$a_1,\\dots,a_m$を$A$の行ベクトルとすると, この問題は未知の線形関数$f\\colon x \\mapsto s^\\top x$のノイズ付きのサンプル$(a_1,f(a_1)+e_1),\\dots,(a_m,f(a_m)+e_m)$が与えられたときに, 未知の線形関数$f$を復元せよという問題と捉えることができます. ",
    "url": "/nobunote/docs/learning_with_error/#%E5%AD%A6%E7%BF%92%E3%81%A8%E3%81%97%E3%81%A6%E3%81%AElwe%E5%95%8F%E9%A1%8C",
    
    "relUrl": "/docs/learning_with_error/#学習としてのlwe問題"
  },"19": {
    "doc": "Learning with Error",
    "title": "Learning with Error",
    "content": " ",
    "url": "/nobunote/docs/learning_with_error/",
    
    "relUrl": "/docs/learning_with_error/"
  },"20": {
    "doc": "よく使う記号",
    "title": "よく使う記号",
    "content": "しばし使う記法を定義します. | 自然数$n\\in \\mathbb{N}$に対して$[n]={1,\\dots,n}$とします. | 有限集合$S$に対し, $x\\sim S$と書いたとき, 要素$x$は$S$上一様ランダムに選ばれることを意味します. | 例えば$\\Pr_{x\\sim S}[\\cdot]$と書くと, $S$上一様ランダムに選ばれた$x$に関する確率を考えることを意味します. | . | より一般に, 有限集合上の分布$\\nu$に対し, $x\\sim \\nu$と書くと$x$は分布$\\nu$に従って選ばれたことを意味します. | 確率変数$X$に対して$\\supp(X) = \\{ x\\colon \\Pr[X=x]&gt;0 \\}$を$X$の台(サポート)といいます (基本的には$X$として離散的な値をとるもののみを考えます). | アルゴリズム$\\mathcal{A}$と入力$x$に対し, $\\mathcal{A}(x)$はアルゴリズム$\\mathcal{A}$の入力$x$に対する出力を表すことにします. | $\\mathcal{A}$が乱択アルゴリズムの場合は$\\mathcal{A}(x)$は確率変数として扱われます. | . | . ",
    "url": "/nobunote/docs/notation/",
    
    "relUrl": "/docs/notation/"
  },"21": {
    "doc": "平均時計算量",
    "title": "平均時計算量",
    "content": "平均時計算量とは, 計算問題に対してそれが効率的に解ける入力の割合を研究する分野です. 研究対象の性質上, 問題と入力分布のペア(しばし分布問題と呼ばれる)を考えます. 効率的なアルゴリズム(例えば多項式時間アルゴリズム)が, 入力分布に従って生成された入力に対して正解する確率(成功確率)を考え, 成功確率が最大となるようなアルゴリズムやその限界について理解することが目標となります. 具体的な問題としては埋め込みクリーク問題やLWE問題などを考えます. 大まかに分けて平均時計算量は二つの文脈で研究されています. | 計算量的擬似ランダムネスとその応用. 効率的に解ける入力が少なければ少ないほど, その問題の困難性は強いとみなし, 強い困難性を持つ判定問題は計算量的擬似ランダム性を通じて暗号学的プリミティブの構成や乱択アルゴリズムの脱乱択化といった応用を持ちます. 統計的には, $ \\{0,1\\}^n $ 上で一様ランダムに選ばれた$x$と任意の関数$f\\colon \\{0,1\\}^n\\to \\{0,1\\}$に対して, $(x,f(x))$の情報論的エントロピーは$n$ビットです (つまり, ランダム文字列に$f$を適用してもエントロピーは増えない). しかし, $f\\colon \\{0,1\\}^n\\to \\{0,1\\}$が強い困難性を持つ関数ならば, 任意の効率的なアルゴリズムにとって, $x$から$f(x)$を推定するのは難しいので, $f(x)$は$x$とは独立なランダムビットに見えます. 従って$(x,f(x))$の計算量的エントロピーは$n+1$ビットとなります. このように, 驚くべきことに, 強い困難性を持つ問題があれば, 計算量的なエントロピーを増幅させられます. そして, そのような問題を構成するための手法として誤り訂正符号やエクスパンダーグラフなどの組合わせ的, 代数的な概念が積極的に応用されています. | 求解における情報理論と計算量理論のギャップ. 高次元統計学の文脈では最尤推定法で解ける具体的な問題に対し, それが計算量的の意味で効率的に解けるかどうかが議論されます. 例えば埋め込みクリーク問題では, $n$頂点ランダムグラフのランダムな位置に埋め込まれた$k$-クリークを探し出せという問題を考えます. クリークサイズが$k\\gg \\log n$であれば, 高確率でランダムグラフが$k$-クリークを含まないので, $k$頂点部分集合を列挙することにより探索することができます. しかしながら現在のところ, 埋め込みクリーク問題を解く多項式時間アルゴリズムは$k\\ge \\sqrt{n}$の範囲でしか見つかっておらず, $\\log n \\ll k \\ll \\sqrt{n}$の範囲でこの問題が解けるかどうかは重要な未解決問題とされています. また, 埋め込みクリーク問題の計算量的下界を仮定すると, 圧縮センシング, 分布の性質検査, あるゲームのナッシュ均衡の近似, 主成分分析など様々な実用的な問題に対する計算量下界が導出できることが知られています. | . ",
    "url": "/nobunote/docs/average_case_complexity/",
    
    "relUrl": "/docs/average_case_complexity/"
  },"22": {
    "doc": "埋め込みクリーク問題",
    "title": "埋め込みクリーク問題",
    "content": "グラフ$G=(V,E)$に対し, 頂点部分集合$C\\subseteq V$は$\\binom{C}{2}\\subseteq E$を満たすときクリークと呼び, 特に頂点数$k$のクリークを$k$-クリークと呼びます. 入力として与えられたグラフ$G=(V,E)$のクリークのうち頂点数最大のものを求める問題を最大クリーク問題と呼び, 古典的なNP困難問題の一つです. 埋め込みクリーク問題 (Planted Clique Problem)とは, 最大クリーク問題の平均時計算量解析の文脈で現れる問題で, 端的に言うとランダムな場所に大きいクリーク$C$を埋め込まれたランダムグラフが入力として与えられたときに, クリーク$C$を求めよという問題です. この問題の計算量的困難性は, 高次元統計学など幅広い分野の問題の計算量的下界を導くのみならず, 暗号学的プリミティブの構成(一方向性関数)などにも応用されています. 暗号学的プリミティブの安全性は素因数分解やLearning with Errorやその他の代数的な問題の困難性に依拠していますが, 一方で最大クリークといった組み合わせ的な問題の困難性に依拠したプリミティブ(特に公開鍵暗号方式)の構成は知られておらず, 重要な研究テーマと認識されています. ",
    "url": "/nobunote/docs/planted_clique/",
    
    "relUrl": "/docs/planted_clique/"
  },"23": {
    "doc": "埋め込みクリーク問題",
    "title": "背景",
    "content": "最大クリーク問題はNP完全なので最悪時の意味では広くその困難性が信じられています. 実はそれだけではなく, 平均時計算量の意味でも最大クリークは多項式時間で解けないであろうと予想されています. 具体的にはグラフ$G$がErdős–Rényiグラフ からサンプリングされた時に最大クリークを見つけられるかを議論します. 本ページでは$\\calG(n,1/2)$を主に考えます (他の$p$でも似たような議論は適用できます). ランダムグラフ$G\\sim \\mathcal{G}(n,1/2)$は確率$1-o(1)$で最大クリークのサイズが$\\approx 2\\log_2 n$となることが知られています. 一方, 適当な単一頂点からスタートして一つずつ頂点を追加していくと極大クリークが得られますが, このようにして得られる極大クリークの頂点数は高確率で$\\approx \\log_2 n$となることが知られています (ここでの「高確率」とは$G\\sim \\mathcal{G}(n,1/2)$の選択に関する確率). したがって単純な貪欲法は$\\mathcal{G}(n,1/2)$上では最大クリーク問題を近似率$1/2$で解くことになりますが, 実は近似率$0.501$達成する多項式時間アルゴリズムは知られていません. ",
    "url": "/nobunote/docs/planted_clique/#%E8%83%8C%E6%99%AF",
    
    "relUrl": "/docs/planted_clique/#背景"
  },"24": {
    "doc": "埋め込みクリーク問題",
    "title": "問題の定義",
    "content": "$\\mathcal{G}(n,1/2)$上の最大クリーク問題では本質的に, サイズ$2\\log_2 n$のクリークが含まれていることがわかっているグラフが与えられたときにそのクリークを見つけ出せるかが問われていました. そこで, より一般にサイズ$k \\gg \\log n$のクリークが含まれていることがわかっているグラフが与えられたときにその$k$-クリークを見つけ出せるかという問題を考えます. パラメータ$n,k\\in \\mathbb{N}$, $p\\in [0,1]$ (ただし$k\\le n$) に対し, $\\mathsf{PC}(n,p,k)$を以下の手続きによって定まる分布とする. | $G \\sim \\mathcal{G}(n,p)$を生成する. 頂点集合を$V(G)=[n]$とする. | 一様ランダムな$k$-頂点部分集合$C\\sim \\binom{[n]}{k}$を選ぶ. | グラフ$G’=\\left([n],E(G)\\cup \\binom{C}{2}\\right)$に対し, $(G’,C)$を$\\mathsf{PC}(n,p,k)$のサンプルとして出力する. | . 特に$p=1/2$の時は$\\mathsf{PC}(n,p,k)$を省略して$\\mathsf{PC}(n,k)$で表す. LWE問題と同様に, 埋め込みクリーク問題においても探索や判定などの問題設定が考えられています. ",
    "url": "/nobunote/docs/planted_clique/#%E5%95%8F%E9%A1%8C%E3%81%AE%E5%AE%9A%E7%BE%A9",
    
    "relUrl": "/docs/planted_clique/#問題の定義"
  },"25": {
    "doc": "埋め込みクリーク問題",
    "title": "埋め込みクリーク探索問題",
    "content": "探索問題では埋め込まれたクリークを復元せよという問題を考えます. パラメータ$n,k\\in \\mathbb{N}$ (ただし$k\\le n$) に対し, 分布$\\mathsf{PC}(n,k)$に従って選ばれた$(G’,C)$を考える. 入力として$G’$を受け取り, $C$を出力せよという問題を埋め込みクリーク探索問題という. アルゴリズム$\\mathcal{A}$は . \\[\\begin{align*} \\Pr_{(G',C) \\sim \\mathsf{PC}(n,k)}\\left[ \\mathcal{A}(G') = C \\right] \\ge \\gamma \\end{align*}\\] を満たすとき, 埋め込みクリーク探索問題を成功確率$\\gamma$で解くという (もしくは単に成功確率$\\gamma$で埋め込みクリークを探すという). ここでは考えるランダムグラフの辺密度を$1/2$に固定していますが, より一般に$p \\in [0,1]$でパラメタライズされた設定も考えることができます. ",
    "url": "/nobunote/docs/planted_clique/#%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF%E3%82%AF%E3%83%AA%E3%83%BC%E3%82%AF%E6%8E%A2%E7%B4%A2%E5%95%8F%E9%A1%8C",
    
    "relUrl": "/docs/planted_clique/#埋め込みクリーク探索問題"
  },"26": {
    "doc": "埋め込みクリーク問題",
    "title": "埋め込みクリーク判定問題",
    "content": "判定問題ではクリークが埋め込まれたグラフ$G’$をErdős–Rényiグラフ$G(n,1/2)$と識別する問題を考えます. もう少し詳しくいうと, 埋め込みクリーク判定問題ではアルゴリズムの入力として一つのグラフが与えられます. ただしこのグラフは次のどちらかの分布に従って生成されるとします: . | $(G,C) \\sim \\mathsf{PC}(n,k)$に対して$G$. | $G \\sim \\mathcal{G}(n,1/2)$. このとき, アルゴリズムの入力はどちらの分布から生成されたかを当てる問題が判定問題です. | . 出力値が0または1のアルゴリズム$\\mathcal{A}$は . \\[\\begin{align*} \\left| \\Pr_{(G,C) \\sim \\mathsf{PC}(n,k)}[\\mathcal{A}(G) = 1] - \\Pr_{G\\sim \\mathcal{G}(n,1/2)}[\\mathcal{A}(G) = 1] \\right| \\ge \\gamma \\end{align*}\\] を満たすとき, 埋め込みクリーク判定問題をアドバンテージ$\\gamma$で解くという. ",
    "url": "/nobunote/docs/planted_clique/#%E5%9F%8B%E3%82%81%E8%BE%BC%E3%81%BF%E3%82%AF%E3%83%AA%E3%83%BC%E3%82%AF%E5%88%A4%E5%AE%9A%E5%95%8F%E9%A1%8C",
    
    "relUrl": "/docs/planted_clique/#埋め込みクリーク判定問題"
  },"27": {
    "doc": "ペア独立性",
    "title": "確率変数族のペア独立性",
    "content": "確率変数族のペア独立性 (pairwise independence)は計算量理論の文脈では Goldreich-Levinの定理, set lower bound protocol, ハッシュ関数, 擬似ランダム生成器などの文脈でよく使われるテクニックです. 通常の意味での独立性を緩めた概念であり, 少ないランダムネスを用いて多くの確率変数を生成する手法としては典型的なものとなります. 確率変数の列$(X_1,\\dots,X_n)$が独立であるというのは「いくつかの$i$に対し$X_i=x_i$である」という事象が他の確率変数の分布に影響を与えないこととされます. ここでは今後の比較のために, 確率変数族の独立性を以下の形で定義しておきます: . 定義 (独立性) . 確率変数の列$(X_1,\\dots,X_n$)が独立であるとは, 任意のインデックスの部分集合$I= \\{i_1,\\dots,i_k\\}\\subseteq [n]$と$x_{i_1},\\dots,x_{i_k}$に対して以下が成り立つことである: . \\[\\begin{align*} \\Pr \\left[ X_{i_1} = x_{i_1}\\text{ and }\\dots\\text{ and }X_{i_k} = x_{i_k} \\right] = \\prod_{j\\in[k]} \\Pr[X_{i_j}=x_{i_j}]. \\tag{1} \\end{align*}\\] ペア独立性とは, 式(1)が成り立つ部分集合$I$の範囲を任意の部分集合ではなく要素数$2$の部分集合に制限することによって定まる概念です. 定義 (ペア独立性) . 確率変数の列$(X_1,\\dots,X_n$)がペア独立であるとは, 任意の要素数$2$のインデックスの部分集合$0\\le i &lt; j \\le n$と$x_i,x_j$に対して以下が成り立つことである: . \\[\\begin{align*} \\Pr \\left[ \\begin{aligned} X_{i} &amp;= x_{i} \\\\ X_{j} &amp;= x_{j} \\end{aligned} \\right] = \\Pr[X_{i}=x_{i}]\\cdot \\Pr[X_j = x_j]. \\tag{2} \\end{align*}\\] ",
    "url": "/nobunote/docs/tools/pairwise_independent/#%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0%E6%97%8F%E3%81%AE%E3%83%9A%E3%82%A2%E7%8B%AC%E7%AB%8B%E6%80%A7",
    
    "relUrl": "/docs/tools/pairwise_independent/#確率変数族のペア独立性"
  },"28": {
    "doc": "ペア独立性",
    "title": "例1",
    "content": "$X_1,\\dots,X_n$を独立で$\\{0,1\\}$上一様ランダムな確率変数とし, 各$1\\le i &lt; j \\le n$に対して . \\[\\begin{align*} Y_{ij} = X_i + X_j \\bmod 2 \\end{align*}\\] で定まる確率変数族$(Y_{ij})_{1\\le i&lt;j\\le n}$はペア独立です. 証明 簡単のため$n=3$で考えます (一般の$n$についても同様). 任意の$y_{12},y_{23}\\in \\{0,1\\}$に対して . \\[\\begin{align*} \\Pr\\left[ \\begin{aligned} Y_{12}&amp;=y_{12} \\\\ Y_{23}&amp;=y_{23} \\end{aligned} \\right] &amp;= \\Pr\\left[ \\begin{aligned} X_1+X_2&amp;=y_{12} \\pmod 2 \\\\ X_2+X_3&amp;=y_{23} \\pmod 2 \\end{aligned} \\right] \\\\ &amp;= \\Pr\\left[ \\begin{aligned} X_1 &amp;= y_{12} + X_2 \\pmod 2 \\\\ X_3 &amp;= y_{23} + X_2 \\pmod 2 \\end{aligned} \\right] \\\\ &amp;= \\frac{1}{4} \\\\ &amp;= \\Pr[Y_{12}=y_{12}]\\cdot \\Pr[Y_{23}=y_{23}] \\end{align*}\\] を得ます. 三つ目の等式では$X_1,X_2,X_3$の独立性を用いています. 上記の例で$n$ビットのランダムな文字列$(X_1,\\dots,X_n) \\sim \\{0,1\\}^n$を$\\binom{n}{2}$ビットの文字列$(Y_{ij})$\\に変換しています (ただし変換で文字列を延ばす代わりに各ビットの独立性は損なわれるため, 得られる長い文字列を擬似ランダム文字列と呼ぶ). このように, ペア独立性の技法を用いると少ないエントロピーのランダムネスから長い擬似ランダム文字列を生成できます (このアイデアはより一般に擬似ランダム生成器の概念で一般化されます). 例えばこのように生成された長い擬似ランダム文字列を乱択アルゴリズムのランダムシードとして代用することでより少ないランダムネスを用いた乱択アルゴリズムの模倣が可能になります. この模倣の精度をペア独立性を用いて評価していくことになります. ",
    "url": "/nobunote/docs/tools/pairwise_independent/#%E4%BE%8B1",
    
    "relUrl": "/docs/tools/pairwise_independent/#例1"
  },"29": {
    "doc": "ペア独立性",
    "title": "例2. ランダムビットの線形結合",
    "content": "例1と同様に独立に$X_1,\\dots,X_n \\sim \\{0,1\\}$を選びます. 例1では$X_i + X_j$という形を考えていましたが, より一般に$X_{i_1}+\\dots + X_{i_k}$という形を考えてもペア独立性が保たれることが同様にして証明できます. 非空な部分集合$I \\subseteq [n]$に対して . \\[\\begin{align*} Y_I = \\sum_{i\\in I} X_i \\bmod 2 \\end{align*}\\] とすることによって定まる確率変数族$(Y_I)_{I\\ne \\emptyset}$はペア独立性を持つ. 証明 任意の非空な$I \\subseteq[n]$に対して, $X_1,\\dots,X_n\\sim \\{0,1\\}$が独立一様ランダムなので, $Y_I$の周辺分布も$\\{0,1\\}$上で一様となります. また, 相異なる二つの非空な部分集合$I,J\\subseteq[n]$および$a,b \\in \\{0,1\\}$に対して . \\[\\begin{align*} \\Pr \\left[ \\begin{aligned} Y_I &amp;= a \\\\ Y_J &amp;= b \\end{aligned} \\right] &amp;= \\Pr \\left[ \\begin{aligned} Y_{I\\setminus J} + Y_{I\\cap J} &amp;= a \\\\ Y_{J\\setminus I} + Y_{I\\cap J} &amp;= b \\end{aligned} \\right] \\\\ &amp;= \\Pr \\left[ \\begin{aligned} Y_{I\\setminus J} &amp;= a - Y_{I\\cap J} \\\\ Y_{J\\setminus I} &amp;= b - Y_{I\\cap J} \\end{aligned} \\right] \\\\ &amp;= \\frac{1}{4} \\end{align*}\\] 証明 より, 確かにペア独立性を満たします. ここで最後の等式では, $X_i$たちの独立性より, $Y_{I\\setminus J}$と$Y_{J\\setminus I}$が独立であることを用いています ($I\\ne J$より$I\\setminus J$と$J\\setminus I$はどちらも非空であることに注意). $\\square$ . この方法を用いると$n$ビットのエントロピーから長さ$2^n-1$の擬似ランダム文字列を得られるので, 指数的に長さを延ばすことが可能となります. ランダム線形関数としての視点 . 例2の構成で得られる$(Y_I)_{I\\ne \\emptyset}$は, 一様ランダムなベクトル$c \\sim \\mathbb{F}_2^n$に対して線形関数$z \\mapsto \\inprod{c,z}$を考えて その($0$以外での)真理値表としてみなすことができます. この解釈は Goldreich-Levinの定理 の証明において本質的に効いてきます. ",
    "url": "/nobunote/docs/tools/pairwise_independent/#%E4%BE%8B2-%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E3%83%93%E3%83%83%E3%83%88%E3%81%AE%E7%B7%9A%E5%BD%A2%E7%B5%90%E5%90%88",
    
    "relUrl": "/docs/tools/pairwise_independent/#例2-ランダムビットの線形結合"
  },"30": {
    "doc": "ペア独立性",
    "title": "例3. ランダムな直線",
    "content": "要素数$q$の有限体$\\mathbb{F}_q$に対して一様ランダムに$a,b\\sim \\mathbb{F}_q$を選び, 各$i\\in \\mathbb{F}_q$に対して . \\[\\begin{align*} X_i = a i + b \\end{align*}\\] として確率変数族$(X_i)_{i\\in \\mathbb{F}_q}$を定めると$(X_i)$はペア独立です. 証明 任意の相異なる$\\mathbb{F}_q$の元$i,j$および$c,d \\in \\mathbb{F}_q$に対して . \\[\\begin{align*} \\Pr \\left[ \\begin{aligned} X_i &amp;= c \\\\ X_j &amp;= d \\end{aligned} \\right] &amp;= \\Pr_{a,b\\sim \\mathbb{F}_q} \\left[ \\begin{aligned} ai+b &amp;= c \\\\ aj+b &amp;= d \\end{aligned} \\right] \\\\ &amp;= \\Pr_{a,b\\sim \\mathbb{F}_q} \\left[ \\begin{bmatrix} i &amp; 1 \\\\ j &amp; 1 \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\end{bmatrix} = \\begin{bmatrix} c \\\\ d \\end{bmatrix} \\right] \\end{align*}\\] ここで, $i\\ne j$より行列 . \\[\\begin{align*} \\begin{bmatrix} i &amp; 1 \\\\ j &amp; 1 \\end{bmatrix} \\end{align*}\\] は逆行列を持つ (Vandermonde行列の特殊ケース) ので, 最後の等式の確率の中身は$a=\\ast,b=\\ast$の形で書けます. $a,b$は一様ランダムなので, この確率は$1/q^2$です. 一方で, ランダムな$a,b\\sim \\mathbb{F}_q$と固定した$i\\in \\mathbb{F}_q$に対し$X_i=ai+b$の周辺分布は$\\mathbb{F}_q$上一様なので, 確かに$(X_i)$はペア独立です. ランダムな直線に基づく生成はランダムな$a,b\\sim \\mathbb{F}_q$を受け取って$q$個の$\\mathbb{F}_q$の元を出力しています. ",
    "url": "/nobunote/docs/tools/pairwise_independent/#%E4%BE%8B3-%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E3%81%AA%E7%9B%B4%E7%B7%9A",
    
    "relUrl": "/docs/tools/pairwise_independent/#例3-ランダムな直線"
  },"31": {
    "doc": "ペア独立性",
    "title": "性質",
    "content": "独立な確率変数の和の分散はそれぞれの確率変数の分散の和に等しいことが知られていますが, この性質はペア独立な確率変数の和についても成り立ちます. $X_1,\\dots,X_n$をペア独立な確率変数とし, $S=\\sum_{i\\in[n]} X_i$とすると, $\\Var[S] = \\sum_{i\\in[n]} \\Var[X_i]$が成り立つ. 証明 確率変数はシフト(定数$a$に対して$X$を$X+a$に変換する操作)に対して分散は変わらないので, $X_i$の期待値を$0$にシフトしても一般性を失いません. このとき, $S$の期待値は$0$なので, その分散は$\\E[S^2]$に等しくなります. また, $X_i$たちはペア独立なので, $i\\ne j$に対して$\\E[X_iX_j]=\\E[X_i]\\E[X_j]=0$が成り立ちます. 実際, $i\\ne j$に対して$\\Pr[X_i=x_i \\text{ and }X_j=x_j]=\\Pr[X_i=x_i]\\Pr[X_j=x_j]$だから . \\[\\begin{align*} \\E[X_iX_j] &amp;= \\sum_{x_i,x_j} x_i x_j \\Pr[X_i=x_i \\text{ and }X_j=x_j] \\\\ &amp;= \\sum_{x_i,x_j} x_i x_j \\Pr[X_i=x_i]\\Pr[X_j=x_j] \\\\ &amp;= \\left( \\sum_{x_i} x_i \\Pr[X_i=x_i] \\right) \\left( \\sum_{x_j} x_j \\Pr[X_j=x_j] \\right) \\\\ &amp;= \\E[X_i]\\E[X_j] \\\\ &amp;= 0 \\end{align*}\\] となります. 従って, 期待値の線形性より . \\[\\begin{align*} \\E[S^2] &amp;= \\E\\left[ \\left( \\sum_{i\\in[n]} X_i \\right)^2 \\right] \\\\ &amp;= \\E\\left[ \\sum_{i\\in[n]} X_i^2 + \\sum_{i\\ne j} X_iX_j \\right] \\\\ &amp;= \\sum_{i\\in[n]} \\E[X_i^2] + \\sum_{i\\ne j} \\E[X_iX_j] \\\\ &amp;= \\sum_{i\\in[n]} \\E[X_i^2] \\\\ &amp;= \\sum_{i\\in[n]} \\Var[X_i] &amp; &amp; \\because\\text{ $X_i$の期待値は$0$} \\end{align*}\\] となり主張を得ます. $\\square$ . このことから和$S$の分散が簡単に計算できるため, チェビシェフの不等式より以下を得ます: . $X_1,\\dots,X_n$をペア独立な確率変数とし, $S=\\sum_{i\\in[n]} X_i$とすると, 任意の$a&gt;0$に対して . \\[\\begin{align*} \\Pr\\qty[\\abs{S-\\E[S]}\\ge a] \\le \\frac{\\sum_{i\\in[n]} \\Var[X_i]}{a^2}. \\end{align*}\\] ",
    "url": "/nobunote/docs/tools/pairwise_independent/#%E6%80%A7%E8%B3%AA",
    
    "relUrl": "/docs/tools/pairwise_independent/#性質"
  },"32": {
    "doc": "ペア独立性",
    "title": "ペア独立性",
    "content": " ",
    "url": "/nobunote/docs/tools/pairwise_independent/",
    
    "relUrl": "/docs/tools/pairwise_independent/"
  },"33": {
    "doc": "よく使う不等式",
    "title": "よく使う不等式",
    "content": "確率に関するよく使う不等式を紹介していきます. 基本的には様々な確率集中不等式 (concentration inequality)を紹介していきます. 確率集中不等式とは, 興味の対象となる確率変数が高確率でその期待値もしくは中央値付近の値をとることを主張する結果です. 例えば, 実数値をとり期待値が存在する確率変数$Y$に対して以下の確率 . \\[\\begin{align*} &amp;\\Pr[Y\\ge \\mathbb{E}[Y] + \\delta] \\\\ &amp;\\Pr[Y\\le \\mathbb{E}[Y] - \\delta] \\end{align*}\\] のできるだけ良い上界(もしくは下界)を与えることが目標です. このような確率集中不等式は様々な分野で利用されており, 確率論, 統計学, 情報理論, 機械学習, 理論計算機科学など幅広い分野で利用されています. ",
    "url": "/nobunote/docs/tools/prob_inequalities/",
    
    "relUrl": "/docs/tools/prob_inequalities/"
  },"34": {
    "doc": "よく使う不等式",
    "title": "Markovの不等式",
    "content": "Markovの不等式は最も基本的な集中不等式です. Markovの不等式は非負値をとる任意の確率変数に対して成り立つため汎用性が高いのが特徴です. 一方でその汎用性が高いあまり, Markovの不等式単体で用いると弱い上界を与えることが多いのですが, 後述するChebyshevの不等式, Chernoff限界など様々な確率集中不等式の証明に利用されています. 補題 (Markovの不等式) 非負値をとり期待値が存在する任意の確率変数$X$と任意の$a&gt;0$に対して . \\[\\begin{align*} \\Pr[X\\ge a]\\le \\frac{\\mathbb{E}[X]}{a}. \\end{align*}\\] Markovの不等式とは期待値よりはるかに大きい値をとる確率を上から抑える不等式ですので, 集中不等式の一種といえるでしょう. 証明 ($X$が離散値をとる場合) 期待値の定義より, 任意の$a&gt;0$に対して . \\[\\begin{align*} \\E[X]&amp;=\\sum_{x\\in \\supp(X)}x\\cdot \\Pr[X=x] \\\\ &amp;\\ge \\sum_{x\\in\\supp(X),x\\ge a}x\\cdot \\Pr[X=x] \\\\ &amp;\\ge a\\cdot \\sum_{x\\in\\supp(X),x\\ge a} \\Pr[X=x] \\\\ &amp;= a\\cdot \\Pr[X\\ge a] \\end{align*}\\] より主張を得る. $\\square$ . $X$が連続値をとる場合についても, $\\sum$を$\\int$に置き換えて同様に示すことができます. マルコフの不等式は基本的に$X$が大きすぎないことを示すために使われますが, 逆に$X$が小さすぎないこ とを示すためにも用いることができます. $X$を$[0,1]$に値をとる確率変数とし, $\\mu = \\E[X] &gt; 0$とすると, 任意の$0\\le \\varepsilon \\le \\mu$に対して . \\[\\begin{align*} \\Pr[X &gt; \\mu-\\varepsilon] \\ge \\frac{\\varepsilon}{1-\\mu+\\varepsilon}\\ge \\varepsilon. \\end{align*}\\] 証明 確率変数$1-X$に対してMarkovの不等式を適用すると . \\[\\begin{align*} \\Pr[X \\le \\mu-\\varepsilon] &amp;= \\Pr[1-X\\ge 1-\\mu+\\varepsilon] \\\\ &amp;\\le \\frac{1-\\mu}{1-\\mu+\\varepsilon} \\\\ &amp;= 1-\\frac{\\varepsilon}{1-\\mu+\\varepsilon} \\end{align*}\\] より主張を得る. $\\square$ . ",
    "url": "/nobunote/docs/tools/prob_inequalities/#markov%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F",
    
    "relUrl": "/docs/tools/prob_inequalities/#markovの不等式"
  },"35": {
    "doc": "よく使う不等式",
    "title": "Chebyshevの不等式",
    "content": "Chebyshevの不等式は分散が小さい確率変数に対する集中性を与える不等式です. Markovの不等式よりも強い上界を与えることができますが, 分散が大きい場合にはMarkovの不等式よりも弱い上界を与えることがあります. 補題 (Chebyshevの不等式) 実数値をとる確率変数$X$と任意の$a&gt;0$に対して . \\[\\begin{align*} \\Pr[|X-\\mathbb{E}[X]|\\ge a]\\le \\frac{\\Var[X]}{a^2}. \\end{align*}\\] 証明 非負の確率変数$(X-\\E[X])^2$に対してMarkovの不等式を適用すると . \\[\\begin{align*} \\Pr[|X-\\E[X]|\\ge a] &amp;= \\Pr[(X-\\E[X])^2\\ge a^2] \\\\ &amp;\\le \\frac{\\E[(X-\\E[X])^2]}{a^2} \\\\ &amp;= \\frac{\\Var[X]}{a^2} \\end{align*}\\] より主張を得る. $\\square$ . ",
    "url": "/nobunote/docs/tools/prob_inequalities/#chebyshev%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F",
    
    "relUrl": "/docs/tools/prob_inequalities/#chebyshevの不等式"
  },"36": {
    "doc": "よく使う不等式",
    "title": "Hoeffdingの不等式",
    "content": "Hoeffdingの不等式は独立な確率変数の和の集中性を与える基本的だが非常に有用な不等式です. 補題 (Hoeffdingの不等式) $X_1,\\dots,X_n$を独立な確率変数, $S=\\sum_{i\\in[n]}X_i$とし, 任意の$i\\in[n]$に対して$0\\le X_i\\le 1$とする. このとき, 任意の$c \\ge 0$に対して . \\[\\begin{align*} \\Pr[S \\ge \\E[S] + c] &amp;\\le \\exp\\left(-\\frac{2c^2}{n}\\right), \\\\ \\Pr[S \\le \\E[S] - c] &amp;\\le \\exp\\left(-\\frac{2c^2}{n}\\right). \\end{align*}\\] ",
    "url": "/nobunote/docs/tools/prob_inequalities/#hoeffding%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F",
    
    "relUrl": "/docs/tools/prob_inequalities/#hoeffdingの不等式"
  },"37": {
    "doc": "よく使う不等式",
    "title": "Chernoffバウンド",
    "content": "Chernoffバウンド (Chernoff bound) はHoeffdingの不等式と同様に, 独立な確率変数の和の集中性を与える不等式です. Hoeffdingの不等式では各確率変数$X_i$が$[0,1]$区間に収まる場合に成り立ちます汎用的な不等式ですが, Chernoffバウンドではさらに$X_i$の期待値の情報を用いた上界を与えているため, 状況によってはHoeffdingの不等式よりも強い上界を与えることができます. 補題 (Chernoff限界) $X_1,\\dots,X_n$を独立な確率変数, $S=\\sum_{i\\in[n]}X_i$とし, 任意の$i\\in[n]$に対して$0\\le X_i\\le 1$とする. このとき, 任意の$c \\ge 0$に対して . \\[\\begin{align*} \\Pr[S \\ge \\E[S] + c] &amp;\\le \\exp\\left(-\\frac{c^2}{2\\E[S] + 2c/3}\\right), \\\\ \\Pr[S \\le \\E[S] - c] &amp;\\le \\exp\\left(-\\frac{c^2}{2\\E[S]}\\right). \\end{align*}\\] Hoeffdingの不等式と比較すると, 期待値$\\E[S]$が小さい場合にはChernoffバウンドの方が強い上界を与えることがわかります. ",
    "url": "/nobunote/docs/tools/prob_inequalities/#chernoff%E3%83%90%E3%82%A6%E3%83%B3%E3%83%89",
    
    "relUrl": "/docs/tools/prob_inequalities/#chernoffバウンド"
  },"38": {
    "doc": "ランダムグラフ",
    "title": "ランダムグラフ",
    "content": "ランダムグラフとはその名の通り, ランダムに生成されたグラフであり, その分布をランダムグラフモデルと呼びます. ",
    "url": "/nobunote/docs/tools/random_graph/",
    
    "relUrl": "/docs/tools/random_graph/"
  },"39": {
    "doc": "ランダムグラフ",
    "title": "Erdős–Rényiグラフ",
    "content": "Erdős–Rényiグラフとは最も基本的なランダムグラフで, 各頂点のペアそれぞれに対し独立にコイントスを行い, その結果に応じて辺で結んで得られるランダムグラフです. 定義 (Erdős–Rényiグラフ). パラメータ$n\\in\\Nat$, $p\\in[0,1]$に対し, Erdős–Rényiグラフとは頂点集合が$[n]= \\{1,\\dots,n\\}$で 各頂点ペアを独立に同じ確率$p$で辺で結んで得られるランダムなグラフで, そのようなランダムグラフの分布を$\\mathcal{G}(n,p)$と表します. すなわち $\\calG(n,p)$とは . \\[\\begin{align*} \\Pr_{G\\sim \\mathcal{G}(n,p)}[G=H] = p^{|E(H)|}\\cdot (1-p)^{\\binom{n}{2} - |E(H)|} \\tag{1} \\end{align*}\\] によって定まる$n$頂点グラフ上の分布です. 特に$p=1/2$のとき, 式(1)の右辺は$H$に依存しない値になるので, $G(n,1/2)$は$n$頂点グラフ全体の集合から一様ランダムに選ばれたグラフとなります. ",
    "url": "/nobunote/docs/tools/random_graph/#erd%C5%91sr%C3%A9nyi%E3%82%B0%E3%83%A9%E3%83%95",
    
    "relUrl": "/docs/tools/random_graph/#erdősrényiグラフ"
  },"40": {
    "doc": "ランダムグラフ",
    "title": "ランダム正則グラフ",
    "content": "ランダム正則グラフとは次数を固定したときの一様ランダムな正則グラフです. 正則グラフとは全ての頂点の次数が等しいグラフのことを意味し, 特にその次数が$d$に等しいグラフを$d$-正則と呼びます. 定義 (ランダム正則グラフ). パラメータ$n,d\\in\\Nat$ (ただし$nd$は偶数)に対してランダム$d$-正則グラフ$G_{n,d}$とは, $n$頂点$d$-正則グラフ全体の中から一様ランダムに選ばれたグラフであり, その分布を$\\calG_{n,d}$で表す. ",
    "url": "/nobunote/docs/tools/random_graph/#%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E6%AD%A3%E5%89%87%E3%82%B0%E3%83%A9%E3%83%95",
    
    "relUrl": "/docs/tools/random_graph/#ランダム正則グラフ"
  }
}
